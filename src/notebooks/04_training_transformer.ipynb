{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjyJdsL4GprB"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of9ofbKGf1zc"
      },
      "source": [
        "install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6H5D7hVCbBs",
        "outputId": "4d8b0cf7-3c22-4607-ce92-b31b6de676dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyyaml==5.4.1 in /usr/local/lib/python3.7/dist-packages (5.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pojKz-Fef4mm"
      },
      "source": [
        "import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqxFJYXu-UIt"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay\n",
        "from sklearn import svm, neighbors, ensemble, neural_network, linear_model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from os.path import exists\n",
        "import os \n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lBUwqgXg5NF"
      },
      "source": [
        "settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_wqperiQ4Zn",
        "outputId": "0112ac39-abda-472f-9cb4-ae2e7a1e8b41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "model_name = 'nli-mpnet-base-v2'\n",
        "train_dataset = 'train_clean_with_emoticons'\n",
        "validation_dataset = train_dataset.replace('train', 'validation')\n",
        "\n",
        "# use for local\n",
        "#dataset_path = '../datasets'\n",
        "#embeddings_path = '../embeddings'\n",
        "#model_path = '../model'\n",
        "\n",
        "# use for google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dataset_path = 'drive/MyDrive/Colab Notebooks/siap/datasets' \n",
        "embeddings_path = 'drive/MyDrive/Colab Notebooks/siap/embeddings'\n",
        "model_path = 'drive/MyDrive/Colab Notebooks/siap/model_augmented'\n",
        "assert os.path.isdir(dataset_path)\n",
        "assert os.path.isdir(embeddings_path)\n",
        "assert os.path.isdir(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbY1pjybh1GY"
      },
      "source": [
        "utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxBJDSpgh4df"
      },
      "outputs": [],
      "source": [
        "def read_pickle(path):\n",
        "  with open(path, \"rb\") as f:\n",
        "    return pickle.load(f)\n",
        "\n",
        "def write_pickle(path, object):\n",
        "  with open(path, \"wb\") as f:\n",
        "    return pickle.dump(object, f)\n",
        "\n",
        "def get_indices(condition, array):\n",
        "    return [i for i, elem in enumerate(array) if condition(elem)]\n",
        "    \n",
        "def filter_by_indices(indices, to_filter):\n",
        "    return [l for i, l in enumerate(to_filter) if i in indices]\n",
        "\n",
        "def show_confusion_matrix(conf_matrix, label_names, title=''):\n",
        "  fig, ax = plt.subplots(figsize=(10, 10))\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix,display_labels=label_names)\n",
        "  disp.plot(include_values=True,cmap=plt.cm.Blues, ax=ax, values_format=None)\n",
        "  if title:\n",
        "    plt.title(title)\n",
        "  plt.show()\n",
        "\n",
        "def get_embeddings_df(model_name, dataset_name, column_name, df):\n",
        "  embedding_file_name = f'{column_name}_{dataset_name}_{model_name}.pkl'\n",
        "  embeddings_file_path = os.path.join(embeddings_path, embedding_file_name) \n",
        "  if exists(embeddings_file_path):\n",
        "    print('reading from pickle...')\n",
        "    return read_pickle(embeddings_file_path)\n",
        "  else:\n",
        "    print('calculating...')\n",
        "    model = SentenceTransformer(model_name)\n",
        "    embeddings = model.encode(list(df[column_name].values))\n",
        "    write_pickle(embeddings_file_path, embeddings)\n",
        "    return embeddings\n",
        "\n",
        "def get_embeddings(reviews, embeddings_file_path):\n",
        "  if exists(embeddings_file_path):\n",
        "    print('reading from pickle...')\n",
        "    return read_pickle(embeddings_file_path)\n",
        "  else:\n",
        "    print('calculating...')\n",
        "    model = SentenceTransformer(model_name)\n",
        "    embeddings = model.encode(reviews)\n",
        "    write_pickle(embeddings_file_path, embeddings)\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrJ-LAVsg7Hq"
      },
      "source": [
        "read dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7espz6Cm_dmg"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(os.path.join(dataset_path, f'{train_dataset}.csv'))\n",
        "df_validation = pd.read_csv(os.path.join(dataset_path, f'{validation_dataset}.csv'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FM67a26GYYZ"
      },
      "source": [
        "# Embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRF9W8wP_iMW",
        "outputId": "facb2a00-4bdb-4d8f-cb77-6b51c3a3ae1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reading from pickle...\n",
            "reading from pickle...\n"
          ]
        }
      ],
      "source": [
        "X_train = get_embeddings_df(model_name, train_dataset, 'Review Text', df_train)\n",
        "y_train = df_train['Rating']\n",
        "X_validation = get_embeddings_df(model_name, validation_dataset, 'Review Text', df_validation)\n",
        "y_validation = df_validation['Rating']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XgAkhj-mPR3",
        "outputId": "184d0b57-116e-4217-ff8b-2f20e170c58e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reading from pickle...\n"
          ]
        }
      ],
      "source": [
        "paraphrases = read_pickle(os.path.join(dataset_path, 'paraphrases_dict_final.pkl'))\n",
        "paraphrases_list = [review for batch in paraphrases.values() for review in batch]\n",
        "paraphrases_embeddings = get_embeddings(paraphrases_list, 'paraphrases_no_5_ratings_times_5.pkl')\n",
        "\n",
        "y_paraphrases = []\n",
        "num_paraphrases = 5\n",
        "for review_id in paraphrases.keys():\n",
        "  rating = df_train[df_train['Review ID'] == review_id]['Rating'].values[0]\n",
        "  for i in range(num_paraphrases):\n",
        "    y_paraphrases.append(rating)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Ook8YLxM0hK_"
      },
      "outputs": [],
      "source": [
        "paraphrases_embeddings_np = np.array(paraphrases_embeddings)\n",
        "y_paraphrases_np = np.array(y_paraphrases)\n",
        "\n",
        "X_train = np.concatenate((X_train, paraphrases_embeddings_np), axis=0)\n",
        "y_train = np.concatenate((y_train, y_paraphrases_np), axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYVwwfYqGZmy"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6WmcfwRA1Hs",
        "outputId": "3d6cf537-29f6-49c1-9d0f-f4bb9e4877a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train >>> 0.6674819971605973\n",
            "Validation >>> 0.610079575596817\n",
            "===========================================\n"
          ]
        }
      ],
      "source": [
        "clf_model_name = 'svm_linear_c1_augmented'\n",
        "\n",
        "clf = svm.SVC(kernel='linear', random_state=1, C=1) # svm_linear_c1\n",
        "#clf = svm.SVC(kernel='rbf', C=0.1, random_state=1)\n",
        "#clf = neighbors.KNeighborsClassifier()\n",
        "#clf = ensemble.RandomForestClassifier(n_estimators=300, max_depth=10)\n",
        "#clf = neural_network.MLPClassifier(random_state=1, early_stopping=True, alpha=0.01, hidden_layer_sizes=[600, 600, 600])\n",
        "#clf = linear_model.LogisticRegressionCV(multi_class='multinomial')\n",
        "#clf = LinearRegression(n_jobs = -1) # linear_regression\n",
        " \n",
        "model_file_path = os.path.join(model_path, clf_model_name + '.pkl')\n",
        "y_train_pred_path = os.path.join(model_path, clf_model_name + '_y_train_pred' + '.pkl')\n",
        "y_validation_pred_path = os.path.join(model_path, clf_model_name + '_y_validation_pred' + '.pkl')\n",
        "\n",
        "if os.path.exists(model_file_path):\n",
        "  clf = read_pickle(model_file_path)\n",
        "  y_train_pred = read_pickle(y_train_pred_path)\n",
        "  y_validation_pred = read_pickle(y_validation_pred_path)\n",
        "else:\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_train_pred = clf.predict(X_train)\n",
        "  y_validation_pred = clf.predict(X_validation)\n",
        "\n",
        "  write_pickle(model_file_path, clf)\n",
        "  write_pickle(y_train_pred_path, y_train_pred)\n",
        "  write_pickle(y_validation_pred_path, y_validation_pred)\n",
        "\n",
        "if clf_model_name == 'linear_regression':\n",
        "  y_train_pred = list(map(lambda x: round(x), y_train_pred))\n",
        "  y_validation_pred = list(map(lambda x: round(x), y_validation_pred))\n",
        "\n",
        "print('Train >>>', f1_score(y_train, y_train_pred, average='micro'))\n",
        "print('Validation >>>', f1_score(y_validation, y_validation_pred, average='micro'))\n",
        "print('===========================================')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "gi5ZgTEqZgRL"
      },
      "outputs": [],
      "source": [
        "if clf_model_name == 'linear_regression':\n",
        "  plt.hist(y_validation_pred)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Y6-DbhzGasAi"
      },
      "outputs": [],
      "source": [
        "if clf_model_name == 'linear_regression':\n",
        "  plt.hist(y_validation)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2aUCwFyIlMw"
      },
      "source": [
        "Tried to reduce dimension of review vectors to 10/15/20 but gives only 0.6 f1 validation score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYPSsY2wGdWI"
      },
      "source": [
        "# Analyze predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GJVa5KbYk1w"
      },
      "source": [
        "## Classification report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTLb8FSEF9av"
      },
      "source": [
        "F1 score types: \n",
        "\n",
        "1. micro -\n",
        "Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
        "\n",
        "2. macro -\n",
        "Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
        "\n",
        "3. weighted -\n",
        "Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkfpjrFlACFH",
        "outputId": "91d6e7a5-8ebb-4cfc-8ef5-878b358ff44f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.64      0.48      0.55      3942\n",
            "           2       0.57      0.39      0.46      7422\n",
            "           3       0.54      0.58      0.56     13556\n",
            "           4       0.71      0.80      0.75     23505\n",
            "           5       0.80      0.76      0.78     10038\n",
            "\n",
            "    accuracy                           0.67     58463\n",
            "   macro avg       0.65      0.60      0.62     58463\n",
            "weighted avg       0.66      0.67      0.66     58463\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Training')\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "006pXnWCXoyw",
        "outputId": "788b7623-2de2-4937-9c63-aff82581ddcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.42      0.30      0.35        82\n",
            "           2       0.33      0.22      0.26       157\n",
            "           3       0.43      0.50      0.46       282\n",
            "           4       0.40      0.55      0.46       495\n",
            "           5       0.83      0.73      0.78      1246\n",
            "\n",
            "    accuracy                           0.61      2262\n",
            "   macro avg       0.48      0.46      0.46      2262\n",
            "weighted avg       0.64      0.61      0.62      2262\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Validation')\n",
        "print(classification_report(y_validation, y_validation_pred, target_names=['1', '2', '3', '4', '5']))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "pro_yj97Yn3I",
        "gDJksFTIYrYc"
      ],
      "name": "training_transformer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
